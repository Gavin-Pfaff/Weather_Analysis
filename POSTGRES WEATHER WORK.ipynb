{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc400f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#boilerplate\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlalchemy as sql\n",
    "import asyncio\n",
    "from aioambient import API\n",
    "import time\n",
    "import requests\n",
    "from datetime import date\n",
    "from datetime import timedelta\n",
    "from aiohttp import ClientSession, ClientTimeout\n",
    "from tqdm.notebook import tqdm\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "engine = sql.create_engine('postgresql://postgres:Bungee12?@localhost:5123/weather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d034dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#API Creds\n",
    "AMBIENT_ENDPOINT= 'https://rt.ambientweather.net/v1'\n",
    "AMBIENT_API_KEY= \"a512d39b3b324d8ba24b03d9e01af46fbbba64ea47054dfb8f8b6530134e2655\"\n",
    "AMBIENT_APPLICATION_KEY= \"e0024179c314412784c8424ae70c1d50d7ff6afd930e48e4b1a12a67535df87c\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27445386",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b56299",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrieve MAC Addresses\n",
    "URL = \"https://api.ambientweather.net/v1/devices\"\n",
    "params = {'applicationKey': AMBIENT_APPLICATION_KEY, 'apiKey': AMBIENT_API_KEY}\n",
    "response = requests.get(URL, params=params)\n",
    "print(f\"Status Code: {response.status_code}\")\n",
    "print(f\"Response: {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175713cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc33f33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cf184c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Establish dateranges for ingestion\n",
    "test_date = date(2022,3,15)\n",
    "handshake_date_out = date(2025,1,21)\n",
    "handshake_date_in = date(2025,1,21)\n",
    "tenure_one = handshake_date_out - test_date\n",
    "tenure_two = date.today() - handshake_date_in\n",
    "delta = date.today()-test_date\n",
    "print(tenure_one)\n",
    "print(tenure_two)\n",
    "print(delta.days)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6941f4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Stage adresses\n",
    "#MAC NEW UNIT\n",
    "api = API(AMBIENT_APPLICATION_KEY, AMBIENT_API_KEY)\n",
    "devices = await api.get_devices()\n",
    "data = await api.get_device_details('48:E7:29:69:C1:25', end_date=date.today())\n",
    "data = pd.DataFrame(data)\n",
    "print(data)\n",
    "#MAC OLD UNIT\n",
    "api = API(AMBIENT_APPLICATION_KEY, AMBIENT_API_KEY)\n",
    "devices = await api.get_devices()\n",
    "data = await api.get_device_details('98:CD:AC:23:0B:C5', end_date=date(2025, 1, 21))\n",
    "data = pd.DataFrame(data)\n",
    "print(data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb09e6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ingest New Sensor\n",
    "timeout = ClientTimeout(total=60)  \n",
    "session = ClientSession(timeout=timeout)\n",
    "api = API(AMBIENT_APPLICATION_KEY, AMBIENT_API_KEY)\n",
    "tenure_two_domain = range(tenure_two.days,0,-1)\n",
    "devices = await api.get_devices()\n",
    "with tqdm(total=tenure_two.days, desc=\"Starting Upload...\") as pbar:\n",
    "    for t in tenure_two_domain:\n",
    "        diff=timedelta(t)\n",
    "        day_slide = date.today()-diff\n",
    "        report = day_slide.isoformat()\n",
    "        pbar.set_description(f\"Day Uploading:{report}\")\n",
    "        data = await api.get_device_details('48:E7:29:69:C1:25', end_date=day_slide)\n",
    "        data = pd.DataFrame(data)\n",
    "        data.drop('yearlyrainin', axis = 1, inplace = True)\n",
    "        data.to_sql('weather_time_series_5min', engine, if_exists = 'append', index =False, method='multi')\n",
    "        pbar.update(1)\n",
    "        await asyncio.sleep(10)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f324a5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ingest Old Sensor\n",
    "timeout = ClientTimeout(total=60)  \n",
    "session = ClientSession(timeout=timeout)\n",
    "api = API(AMBIENT_APPLICATION_KEY, AMBIENT_API_KEY)\n",
    "tenure_one_domain = range(tenure_one.days,0,-1)\n",
    "devices = await api.get_devices()\n",
    "with tqdm(total=tenure_one.days, desc=\"Starting Upload...\") as pbar:\n",
    "    for t in tenure_one_domain:\n",
    "        diff=timedelta(t)\n",
    "        day_slide = handshake_date_out-diff\n",
    "        report = day_slide.isoformat()\n",
    "        pbar.set_description(f\"Day Uploading: {report}\")\n",
    "        data = await api.get_device_details('98:CD:AC:23:0B:C5', end_date=day_slide)\n",
    "        data = pd.DataFrame(data)\n",
    "        data.to_sql('weather_time_series_5min', engine, if_exists = 'append', index =False, method='multi')\n",
    "        pbar.update(1)\n",
    "        await asyncio.sleep(10)\n",
    "    #check august 11th 2022, feb 2024 for inconsistencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80050c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ingest any new entries\n",
    "#need to drop yearlyrainin as did not exist in old data model -- backfill?\n",
    "timeout = ClientTimeout(total=60)  \n",
    "session = ClientSession(timeout=timeout)\n",
    "api = API(AMBIENT_APPLICATION_KEY, AMBIENT_API_KEY)\n",
    "\n",
    "prev_update = pd.read_sql(\"SELECT MAX(date) FROM weather_time_series_5min\", engine)\n",
    "prev_update = prev_update['max'].loc[0].date()\n",
    "today = date.today()\n",
    "backfill = today - prev_update\n",
    "\n",
    "\n",
    "devices = await api.get_devices()\n",
    "with tqdm(total=backfill.days, desc=\"Starting Upload...\") as pbar:\n",
    "    for t in range(backfill.days,0,-1):\n",
    "        diff=timedelta(t)\n",
    "        day_slide = today-diff\n",
    "        report = day_slide.isoformat()\n",
    "        pbar.set_description(f\"Day Uploading: {report}\")\n",
    "        data = await api.get_device_details('48:E7:29:69:C1:25', end_date=day_slide)\n",
    "        data = pd.DataFrame(data)\n",
    "        data.drop('yearlyrainin', axis = 1, inplace = True)\n",
    "        data.to_sql('weather_time_series_5min', engine, if_exists = 'append', index =False, method='multi')\n",
    "        pbar.update(1)\n",
    "        await asyncio.sleep(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1adee16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test for last update on table\n",
    "\n",
    "pd.read_sql(\"SELECT MAX(date) FROM weather_time_series_5min\", engine)\n",
    "prev_update = pd.read_sql(\"SELECT MAX(date) FROM weather_time_series_5min\", engine)\n",
    "prev_update = prev_update['max'].loc[0].date()\n",
    "today = date.today()\n",
    "print(prev_update)\n",
    "backfill = today - prev_update\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9173830b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce691012",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#convert date column from text to Timestamp and verify\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(sql.text('ALTER TABLE \"weather_time_series_5min\" ALTER COLUMN \"date\" TYPE TIMESTAMP USING \"date\"::timestamp'))\n",
    "    conn.commit()\n",
    "datecheck = pd.read_sql(\"SELECT data_type FROM information_schema.columns WHERE table_name = 'weather_time_series_5min' AND column_name = 'date'\", engine)\n",
    "print(datecheck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3c4dff",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#with engine.connect() as conn:\n",
    "    #conn.execute(sql.text('SELECT * FROM weather_time_series_5min ORDER BY date'))\n",
    "    #conn.commit()\n",
    "\n",
    "datecheck = pd.read_sql('SELECT date FROM weather_time_series_5min ORDER BY date', engine)\n",
    "print(datecheck.head(100).to_string())\n",
    "\n",
    "#look into Clustering or DB partitioning for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54c4538",
   "metadata": {},
   "outputs": [],
   "source": [
    "#deduplicate\n",
    "print(len(pd.read_sql('SELECT * FROM weather_time_series_5min',engine)))\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(sql.text('DELETE FROM weather_time_series_5min WHERE ctid NOT IN (SELECT min(ctid) FROM weather_time_series_5min GROUP BY date)'))\n",
    "    conn.commit()\n",
    "print(len(pd.read_sql('SELECT * FROM weather_time_series_5min',engine)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5a706d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#build date-index for the time series\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(sql.text('DROP TABLE sleuth'))\n",
    "    conn.execute(sql.text('CREATE TABLE sleuth AS SELECT DISTINCT date_trunc(\\'day\\', date ) AS sleuth_day FROM weather_time_series_5min ORDER BY sleuth_day'))\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcb3f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#window analysis to find data breaks\n",
    "gaps = pd.read_sql('SELECT sleuth_day AS gap_start, LEAD(sleuth_day) OVER (ORDER BY sleuth_day) AS gap_end, LEAD(sleuth_day) OVER (ORDER BY sleuth_day) - sleuth_day - INTERVAL \\'1 day\\' AS gap_duration FROM sleuth', engine )\n",
    "gaps = gaps.loc[gaps['gap_duration'] != '0 days']\n",
    "print(gaps)\n",
    "#ways to pass the missing days in the range to a loop so we dont have to cover the whole min - max distance on the second pass? can do programatically\n",
    "#looks like there were outages on 7/11,7/12, 8/18, 8/19, 9/16, and 10/17 in 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f832d39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#repopulate\n",
    "gap_patch_down = min(gaps['gap_start'])\n",
    "gap_patch_up = max(gaps['gap_end'])\n",
    "gap_patch = gap_patch_up - gap_patch_down\n",
    "timeout = ClientTimeout(total=60)  \n",
    "session = ClientSession(timeout=timeout)\n",
    "api = API(AMBIENT_APPLICATION_KEY, AMBIENT_API_KEY)\n",
    "gap_domain = range(gap_patch.days,0,-1)\n",
    "devices = await api.get_devices()\n",
    "with tqdm(total=gap_patch.days, desc=\"Starting Upload...\") as pbar:\n",
    "    for t in gap_domain:\n",
    "        diff=timedelta(t)\n",
    "        day_slide = gap_patch_up-diff\n",
    "        report = day_slide.isoformat()\n",
    "        pbar.set_description(f\"Day Uploading: {report}\")\n",
    "        data = await api.get_device_details('98:CD:AC:23:0B:C5', end_date=day_slide)\n",
    "        data = pd.DataFrame(data)\n",
    "        data.to_sql('weather_time_series_5min', engine, if_exists = 'append', index =False, method='multi')\n",
    "        pbar.update(1)\n",
    "        await asyncio.sleep(10)\n",
    "#afterward run dedupe again +check for gaps over and data should be clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7e5c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_sql(\"SElECT tablename FROM pg_tables WHERE schemaname = 'public'\", engine)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fd70ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_hist = pd.read_sql(\"SELECT column_name FROM information_schema.columns WHERE table_name = 'weather_time_series_5min'\" , engine)\n",
    "print(temp_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46dced00",
   "metadata": {},
   "outputs": [],
   "source": [
    "gap_patch_down = min(gaps['gap_start'])\n",
    "gap_patch_up = max(gaps['gap_end'])\n",
    "gap_patch = gap_patch_up - gap_patch_down\n",
    "gap_domain = range(gap_patch.days,0,-1)\n",
    "diff=timedelta(t)\n",
    "day_slide = gap_patch_down-diff\n",
    "print(day_slide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bef41bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#refresh gapfinder\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(sql.text('DROP TABLE sleuth'))\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fc1c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "scan = date(2023,7,14)\n",
    "data = await api.get_device_details('98:CD:AC:23:0B:C5', end_date=scan)\n",
    "data = pd.DataFrame(data)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526475ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e749ac9d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#convert time zone and analyze \n",
    "temp_series=pd.read_sql('SELECT tempf, date AT TIME ZONE \\'UTC\\' AT TIME ZONE \\'America/Los_Angeles\\'AS date FROM weather_time_series_5min ORDER BY date ', engine)\n",
    "plt.style.use('_mpl-gallery')\n",
    "plt.figure(figsize = (24,10))\n",
    "plt.plot('date', 'tempf', data = temp_series)\n",
    "temp_low = np.nanmin(temp_series['tempf'])\n",
    "temp_high = np.nanmax(temp_series['tempf'])\n",
    "print('Record Low:')\n",
    "print(temp_series.loc[temp_series['tempf'] == temp_low])\n",
    "print('Record High:')\n",
    "print(temp_series.loc[temp_series['tempf'] == temp_high])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccfb64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9717a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to fix that hole where the sensor was inside -- going to do an average of the two previous years point-wise observations -- smoother on the whole data set afterward may be appropriate but I like the noisy data, shows temp bands well \n",
    "#overlay a smoothed day and night curve---\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(sql.text('DROP VIEW IF EXISTS day_temp'))\n",
    "    conn.execute(sql.text('CREATE VIEW day_temp AS SELECT tempf, AVG(tempf) OVER (ORDER BY date ROWS BETWEEN 24 PRECEDING AND 24 FOLLOWING) AS temp_MA, date AT TIME ZONE \\'UTC\\' AT TIME ZONE \\'America/Los_Angeles\\' AS date FROM weather_time_series_5min WHERE EXTRACT(HOUR FROM date AT TIME ZONE \\'UTC\\' AT TIME ZONE \\'America/Los_Angeles\\') BETWEEN 7 AND 19 ORDER BY date'))\n",
    "    \n",
    "    \n",
    "    conn.execute(sql.text('DROP VIEW IF EXISTS night_temp'))\n",
    "    conn.execute(sql.text('CREATE VIEW night_temp AS SELECT tempf, AVG(tempf) OVER (ORDER BY date ROWS BETWEEN 24 PRECEDING AND 24 FOLLOWING) AS temp_MA, date AT TIME ZONE \\'UTC\\' AT TIME ZONE \\'America/Los_Angeles\\' AS date FROM weather_time_series_5min WHERE EXTRACT(HOUR FROM date AT TIME ZONE \\'UTC\\' AT TIME ZONE \\'America/Los_Angeles\\') NOT BETWEEN 7 AND 19 ORDER BY date'))\n",
    "    \n",
    "    conn.execute(sql.text('DROP VIEW IF EXISTS avg_day_temp'))\n",
    "    conn.execute(sql.text('CREATE VIEW avg_day_temp AS SELECT AVG(tempf) OVER (PARTITION BY to_char(date AT TIME ZONE \\'UTC\\' AT TIME ZONE \\'America/Los_Angeles\\', \\'dd/mm/yyyy\\')) AS temp_day_avg, to_char(date AT TIME ZONE \\'UTC\\' AT TIME ZONE \\'America/Los_Angeles\\', \\'dd/mm/yy\\') AS day, date AT TIME ZONE \\'UTC\\' AT TIME ZONE \\'America/Los_Angeles\\' AS date FROM weather_time_series_5min WHERE EXTRACT(HOUR FROM date AT TIME ZONE \\'UTC\\' AT TIME ZONE \\'America/Los_Angeles\\') BETWEEN 7 AND 19 ORDER BY date'))\n",
    "    \n",
    "    conn.execute(sql.text('DROP VIEW IF EXISTS avg_night_temp'))\n",
    "    conn.execute(sql.text('CREATE VIEW avg_night_temp AS SELECT AVG(tempf) OVER (PARTITION BY to_char(date AT TIME ZONE \\'UTC\\' AT TIME ZONE \\'America/Los_Angeles\\', \\'dd/mm/yyyy\\')) AS temp_night_avg, to_char(date AT TIME ZONE \\'UTC\\' AT TIME ZONE \\'America/Los_Angeles\\', \\'dd/mm/yy\\') AS day, date AT TIME ZONE \\'UTC\\' AT TIME ZONE \\'America/Los_Angeles\\' AS date FROM weather_time_series_5min WHERE EXTRACT(HOUR FROM date AT TIME ZONE \\'UTC\\' AT TIME ZONE \\'America/Los_Angeles\\') NOT BETWEEN 7 AND 19 ORDER BY date'))\n",
    "    \n",
    "    conn.commit()\n",
    "\n",
    "\n",
    "\n",
    "dayview = pd.read_sql('SELECT * from day_temp', engine)\n",
    "nightview = pd.read_sql('SELECT * from night_temp', engine)\n",
    "\n",
    "dayagview = pd.read_sql('SELECT * from avg_day_temp', engine)\n",
    "\n",
    "print(dayview.head(10).to_string())\n",
    "print(nightview.head(10).to_string())\n",
    "print(dayagview.head(500).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5dfea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##plot sidebyside day and nite to understand diurnal comp/reduce noise\n",
    "temp_series_day=pd.read_sql('SELECT * FROM day_temp ORDER BY date ', engine)\n",
    "temp_series_night=pd.read_sql('SELECT * FROM night_temp ORDER BY date', engine)\n",
    "day_ag = pd.read_sql('SELECT * FROM avg_day_temp ORDER BY date', engine)\n",
    "night_ag = pd.read_sql('SELECT * FROM avg_night_temp ORDER BY date', engine)\n",
    "\n",
    "temp_low_day = np.nanmin(temp_series_day['tempf'])\n",
    "temp_high_day = np.nanmax(temp_series_day['tempf'])\n",
    "temp_low_night = np.nanmin(temp_series_night['tempf'])\n",
    "temp_high_night = np.nanmax(temp_series_night['tempf'])\n",
    "plt.style.use('_mpl-gallery')\n",
    "plt.figure(figsize = (24,10))\n",
    "\n",
    "\n",
    "plt.plot('date', 'tempf', data = temp_series_day)\n",
    "plt.plot('date', 'temp_day_avg', color = 'r', data = day_ag, linewidth=2)\n",
    "\n",
    "#print('Daytime Record Low:')\n",
    "#print(temp_series.loc[temp_series_day['tempf'] == temp_low_day])\n",
    "#print('Daytime Record High:')\n",
    "#print(temp_series.loc[temp_series_day['tempf'] == temp_high_day])\n",
    "\n",
    "\n",
    "plt.plot('date', 'tempf', data = temp_series_night)\n",
    "plt.plot('date', 'temp_night_avg', color = 'm', data = night_ag, linewidth=2)\n",
    "\n",
    "\n",
    "\n",
    "#print('Nighttime Record Low:')\n",
    "#print(temp_series.loc[temp_series_night['tempf'] == temp_low_night])\n",
    "#print('Nighttime Record High:')\n",
    "#print(temp_series.loc[temp_series_night['tempf'] == temp_high_night])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664a4267",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
